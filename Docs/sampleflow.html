<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="utf-8">
      <link rel="STYLESHEET" href="https://www.spec.org/cpu2017/Docs/css/cpudocs.css" type="text/css">
      <style>
li {margin-top:.2em;}
      </style>
      <title>747.sampleflow_r</title>
   </head>

   <body>
      <div style="text-align: center">
         <h1>747.sampleflow_r<br>
            SPEC CPU&reg;v8 Benchmark Description</h1>

      </div>

      <h3>Benchmark Name</h3>

      <p>747.sampleflow_r</p>


      <h3 id="authors">Benchmark Authors</h3>

      <p>Wolfgang Bangerth &lt;bangerth at gmail dot com&gt;, Colorado State University.</p>

      <p>The benchmark contains the deal.II library in a simplified version, primarily stripping out all external
      dependencies. Many people have contributed over the past 25 years to deal.II, see its list of 
      <a href="https://dealii.org/authors.html" class="external">authors</a>.

      <p>The benchmark also contains the SampleFlow library; the list of
      authors for SampleFlow can be found at 
      <a href="https://github.com/bangerth/SampleFlow/graphs/contributors">
         https://github.com/bangerth/SampleFlow/graphs/contributors</a>.

      <p>Finally, deal.II contains a stripped-down version of
      <a href="https://www.boost.org/" class="external">BOOST</a>.</p>


      <h3 id="category">Benchmark Program General Category</h3>

      <p>Monte Carlo sampling for an inverse problem involving partial differential equations.</p>


      <h3 id="description">Benchmark Description</h3>

         <p>747.sampleflow is a benchmark for the SPEC CPUv8 test suite that is based on the deal.II and SampleFlow
         libraries, see <a href="https://www.dealii.org" class="external">https://www.dealii.org</a> and 
         <a href="https://github.com/bangerth/sampleFlow/" class="external">https://github.com/bangerth/sampleFlow/</a>.  The
         deal.II library has previously already served as the basis for 
         <a href="https://www.spec.org/cpu2006/Docs/447.dealII.html" class="external">447.dealIIi</a> in SPEC CPU 2006 and 
         <a href="https://www.spec.org/cpu2017/Docs/benchmarks/510.parest_r.html" class="external">510.parest_r</a> in SPEC
         CPU 2017.</p>

         <p>The current benchmark is an implementation of a testcase that uses a Monte Carlo sampling method to gain
         information about a probability distribution p(x). The definition of the function p(x) involves the solution of a
         partial differential equation using the finite element method. The overall problem this benchmark solves is
         concisely defined in <a href="https://arxiv.org/abs/2102.07263" class="external">this preprint</a> (which has been
         accepted for publication in SIAM Review); it is intended as a problem that is simple enough to solve yet complicated
         enough that one needs sophisticated algorithms to get answers with sufficient accuracy. For example, the "ground
         truth" answers provided in the preprint above were obtained using some 30 CPU years of computations. More
         sophisticated algorithms than those used in the preprint should be able to obtain the same accuracy with far less
         effort, but generally the accuracy one gets is inversely proportional to (the square root of) the computational
         effort and the very large effort made for the results in the paper reflects a desire to have published results with
         as much accuracy as possible.</p>

         <p>This benchmark implements a sampling algorithm for p(x) that is based on a variation of the Differential
         Evaluation algorithm, which is a parallel version of the 
         <a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm" class="external">Metropolis-Hastings
            algorithm</a> In it, a number _N_ of chains are running in parallel, occasionally exchanging information. In the
         version used for this benchmark, _N_ is a parameter that is set in the input file. The resulting algorithm is then
         of the fork-join type: At the beginning of each iteration, _N_ work items are created to generate a new sample on
         each of these chains, and these items can be worked on independently; once done, we start another parallel phase
         where the samples are post-processed.</p> 
         
         <p>The fork-join approach of this benchmark is implemented using a simple C++ std::thread pool that maps tasks on
         available worker threads. It creates as many worker threads as directed by the SPEC CPU toolset, or, in the absence
         of such direction, then as many as <samp>std::thread::hardware_concurrency()</samp> states the machine can
         provide.</p>

      <h3 id="input">Input Description</h3>

      <p>The input files contain two lines, which set the number of samples per chain and the number of chains.  

      <h3 id="output">Output Description</h3>

      <p>The benchmark internally creates a "chain" of samples, i.e., a long sequence of 64-dimensional vectors that have are
      samples from a specific statistical distribution (in the same way as coin flips are samples from a binomial
      distribution heads/tails). From these samples, the program then computes statistics such as the mean value of the
      samples, and these are output.</p>

      <p>The way the samples are computed is via a Monte Carlo method. Monte Carlo methods are often difficult to make
      bit-by-bit reproducible on different platforms because they depend on randomness. The benchmark addresses this in three
      ways: (i) it ensures that *what* is computed is independent of the choice of random numbers and round-off, ensuring the
      exact same load, (ii) it computes statistics that are relatively insensitive to round-off as output quantities to
      ensure correctness of benchmark runs, (iii) in all places where numbers subject to round-off are compared, it first
      casts to lower-precision data types to avoid the vast majority of round-off errors from making a difference.</p>

      <p>The specific statistics that are computed by the program are not directly on the 64-dimensional vectors that are
      internally computed. Rather, the program "pools" the elements of each 64-dimensional vector by adding 16 elements each
      into one number, resulting in one 4-dimensional vector per sample, in order to improve the numerical stability of the
      computation. It then computes the average of these 4-dimensional vectors and outputs this as the "Mean value of the
      4-parameter downscaling" (which is of course also a 4-dimensional vector). The program also computes this quantity by
      first computing the mean of all of the 64-dimensional vectors, and then applying the 16-component summation; this needs
      to result in the same outcome as before and is reported as "Comparison mean value of the downscaled 64-parameter
      mean".</p>

      <p>The output will then look similar to:</p>
      <pre>
      Mean value of the 4-parameter downscaling:
      0.836776 1.13711 1.18733 1.35706
      Comparison mean value of the downscaled 64-parameter mean:
      0.836776 1.13711 1.18733 1.35706
      Number of samples = 900
      </pre>



      <h3 id="language">Programming Language</h3>

      <p>C++</p>

      <h3 id="threads">Threading Model</h3>

         <p>For the SPECspeed version of this benchmark, the fork-join approach is implemented using a simple C++ std::thread
         pool that maps tasks on available worker threads. It creates as many worker threads as directed by the SPEC CPU
         toolset, or, in the absence of such direction, then as many as <samp>std::thread::hardware_concurrency()</samp>
         states the machine can provide.</p>

         <p>The SPECrate version maps all work to a single thread.</p>

      <h3 id="portability">Known Portability Issues</h3>

      <p>None.</p>


      <h3 id="license">Sources and Licensing</h3>

      <p>SampleFlow is licensed under the GNU LGPL 2.1. SampleFlow can be found at 
      <a href="https://github.com/bangerth/SampleFlow/" class="external">https://github.com/bangerth/SampleFlow/</a>.  The
      version of SampleFlow is taken from the master branch in January 2023, but has been modified to use the BOOST ublas
      library instead of the (external) Eigen library for linear algebra operations.</p>

      <p>deal.II is licensed under the GNU LGPL 2.1 or later. Deal.II can be found at
      <a href="https://www.dealii.org" class="external">https://www.dealii.org</a>. The version of deal.II used for this
      benchmark is from a snapshot of the 9.4 release branch between the 9.4.1 and 9.4.2 releases, commit
      6a1115bbf6fbbe1470c88f9352f12513d0d3d37a.</p>

      <p>The copy of deal.II used in this benchmark contains a stripped-down version of BOOST, with minor modifications from
      the version 1.70.0 that was originally imported into deal.II. BOOST is licensed under the 
      <a href="https://www.boost.org/users/license.html">BOOST Software License</a>.</p>

      <p>A detailed version history of this benchmark can be found 
      <a href="https://github.com/bangerth/spec-cpuv8-sampleflow">here</a>.</p>


      <h3 id="references">References</h3>

      <ul>
         <li>A link</li>
         <li>A book</li>
         <li>A magazine article</li>
      </ul>

      <p style="margin-left:0em;border-top:thin solid black;">
      Copyright&nbsp;&copy;&nbsp;2023 Standard Performance Evaluation Corporation (SPEC&reg;)</p>


   </body>
   <!-- vim: set filetype=html syntax=html shiftwidth=3 tabstop=8 expandtab nosmarttab colorcolumn=132: -->
</html>
